{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare joined datasets for meteorology challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_folder = r'..\\datasets'\n",
    "os.chdir(working_folder)  # change to your own folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validity date</th>\n",
       "      <th>City</th>\n",
       "      <th>Persist. value_tmax_1</th>\n",
       "      <th>EC_tmax_1</th>\n",
       "      <th>CO_tmax_1</th>\n",
       "      <th>C3_tmax_1</th>\n",
       "      <th>OH_tmax_1</th>\n",
       "      <th>Persist. value_tmin_1</th>\n",
       "      <th>EC_tmin_1</th>\n",
       "      <th>CO_tmin_1</th>\n",
       "      <th>...</th>\n",
       "      <th>C3_humidity_2</th>\n",
       "      <th>cityID</th>\n",
       "      <th>stationID</th>\n",
       "      <th>name</th>\n",
       "      <th>E</th>\n",
       "      <th>N</th>\n",
       "      <th>elevation</th>\n",
       "      <th>elevationWindMet</th>\n",
       "      <th>CoastalDist</th>\n",
       "      <th>archiveID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.451686e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Afula</td>\n",
       "      <td>35.277</td>\n",
       "      <td>32.596</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>5811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.451772e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Afula</td>\n",
       "      <td>35.277</td>\n",
       "      <td>32.596</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>5811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.451858e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Afula</td>\n",
       "      <td>35.277</td>\n",
       "      <td>32.596</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>5811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.451945e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Afula</td>\n",
       "      <td>35.277</td>\n",
       "      <td>32.596</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>5811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.452031e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Afula</td>\n",
       "      <td>35.277</td>\n",
       "      <td>32.596</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>5811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Validity date  City  Persist. value_tmax_1  EC_tmax_1  CO_tmax_1  \\\n",
       "0   1.451686e+09     0                     12       11.0       11.0   \n",
       "1   1.451772e+09     0                     11       11.0       11.0   \n",
       "2   1.451858e+09     0                     15       14.0       16.0   \n",
       "3   1.451945e+09     0                     16       19.0       17.0   \n",
       "4   1.452031e+09     0                     20       20.0       18.0   \n",
       "\n",
       "   C3_tmax_1  OH_tmax_1  Persist. value_tmin_1  EC_tmin_1  CO_tmin_1  \\\n",
       "0       12.0       13.0                    6.0        7.0        6.0   \n",
       "1       14.0       13.0                    7.0        9.0        8.0   \n",
       "2       14.0       17.0                    6.0        8.0       11.0   \n",
       "3       17.0       20.0                   10.0        9.0       10.0   \n",
       "4       18.0       20.0                    6.0        8.0       12.0   \n",
       "\n",
       "     ...      C3_humidity_2  cityID  stationID   name       E       N  \\\n",
       "0    ...                 35       0         16  Afula  35.277  32.596   \n",
       "1    ...                 51       0         16  Afula  35.277  32.596   \n",
       "2    ...                 58       0         16  Afula  35.277  32.596   \n",
       "3    ...                 49       0         16  Afula  35.277  32.596   \n",
       "4    ...                 45       0         16  Afula  35.277  32.596   \n",
       "\n",
       "   elevation   elevationWindMet  CoastalDist  archiveID  \n",
       "0          60                70        33.34       5811  \n",
       "1          60                70        33.34       5811  \n",
       "2          60                70        33.34       5811  \n",
       "3          60                70        33.34       5811  \n",
       "4          60                70        33.34       5811  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding city data from the IMS' site\n",
    "joined_train = pd.read_pickle(r'joined_train_12_df.pickle')\n",
    "joined_test = pd.read_pickle(r'joined_test_12_df.pickle')\n",
    "stationsData = pd.read_csv(r'stations_dist.csv')\n",
    "joined_train = joined_train.merge(stationsData, left_on='City', right_on='cityID',how='outer')\n",
    "joined_test = joined_test.merge(stationsData, left_on='City', right_on='cityID',how='outer')\n",
    "\n",
    "joined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: City_0, dtype: uint8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_train_12_1hot = pd.get_dummies(joined_train, columns=['City'])\n",
    "joined_test_12_1hot = pd.get_dummies(joined_test, columns=['City'])\n",
    "joined_test_12_1hot['City_0'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_train_12_1hot.to_pickle('joined_train_with_metro_data.pickle')\n",
    "joined_test_12_1hot.to_pickle('joined_test_with_metro_data.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "# train sets\n",
    "Tmax_train = pd.read_csv(r'train_maxTemp.csv')\n",
    "Tmin_train = pd.read_csv(r'train_minTemp.csv')\n",
    "Wind_train = pd.read_csv(r'train_Wind.csv')\n",
    "Humidity_train = pd.read_csv(r'train_Humidity.csv')\n",
    "\n",
    "# test sets\n",
    "Tmax_test = pd.read_csv(r'test_maxTemp.csv')\n",
    "Tmin_test = pd.read_csv(r'test_minTemp.csv')\n",
    "Wind_test = pd.read_csv(r'test_Wind.csv')\n",
    "Humidity_test = pd.read_csv(r'test_Humidity.csv')\n",
    "\n",
    "# obs values\n",
    "train_Tmax_obs = pd.read_csv(r'train_label.csv')\n",
    "test_Tmax_obs = pd.read_csv(r'test_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join data sets by keys: Form, Validity date, City\n",
    "# joined_train = pd.merge(Tmax_train, Tmin_train.drop(columns=['Basis date']), on=['Time', 'Validity date', 'City'], suffixes=('_tmax', '_tmin'))\n",
    "\n",
    "\n",
    "joined_train_1 = pd.merge(Tmax_train, Tmin_train, on=['Time', 'Validity date', 'City'], suffixes=('_tmax', '_tmin'))\n",
    "joined_train_2 = pd.merge(joined_train_1, Wind_train, on=['Time', 'Validity date', 'City'], suffixes=('', '_wind'))\n",
    "joined_train = pd.merge(joined_train_2, Humidity_train, on=['Time', 'Validity date', 'City'], suffixes=('', '_humidity'))\n",
    "joined_train.columns = ['Time', 'Basis date_tmax', 'Validity date', 'City',\n",
    "       'Persist. value_tmax', 'EC_tmax', 'CO_tmax', 'C3_tmax', 'OH_tmax',\n",
    "       'Basis date_tmin', 'Persist. value_tmin', 'EC_tmin', 'CO_tmin',\n",
    "       'C3_tmin', 'OH_tmin', 'Basis date_wind', 'Persist. value_wind', 'EC_wind', 'CO_wind', 'C3_wind',\n",
    "       'OH_wind', 'Basis date_humidity', 'Persist. value_humidity', 'EC_humidity',\n",
    "       'C3_humidity']\n",
    "\n",
    "joined_test = pd.merge(Tmax_test, Tmin_test, on=['Time', 'Validity date', 'City'], suffixes=('_tmax', '_tmin'))\n",
    "joined_test = pd.merge(joined_test, Wind_test, on=['Time', 'Validity date', 'City'], suffixes=('', '_wind'))\n",
    "joined_test = pd.merge(joined_test, Humidity_test, on=['Time', 'Validity date', 'City'], suffixes=('', '_humidity'))\n",
    "joined_test.columns = ['Time', 'Basis date_tmax', 'Validity date', 'City',\n",
    "       'Persist. value_tmax', 'EC_tmax', 'CO_tmax', 'C3_tmax', 'OH_tmax',\n",
    "       'Basis date_tmin', 'Persist. value_tmin', 'EC_tmin', 'CO_tmin',\n",
    "       'C3_tmin', 'OH_tmin', 'Basis date_wind', 'Persist. value_wind', 'EC_wind', 'CO_wind', 'C3_wind',\n",
    "       'OH_wind', 'Basis date_humidity', 'Persist. value_humidity', 'EC_humidity',\n",
    "       'C3_humidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting string values to float (the model can fit only float values)\n",
    "\n",
    "# casting 'Validity date' to datetime.timestamp\n",
    "def castDates(df):\n",
    "    df['Validity date'] = df['Validity date'].apply(lambda x: (datetime.strptime(x, '%d-%m-%y')).timestamp())\n",
    "\n",
    "\n",
    "def merge12(df):\n",
    "    df1 = df[df['Time']== 1]\n",
    "    df2 = df[df['Time']== 2]\n",
    "    merged_df = pd.merge(df1, df2, on=['Validity date', 'City'], suffixes=('_1', '_2'))\n",
    "    merged_df.drop(['Time_1', 'Time_2'], axis=1, inplace=True)\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "def drop_basis(df):\n",
    "    return df.drop([x for x in df.columns if x.startswith('Basis date')], axis=1)\n",
    "\n",
    "\n",
    "def prepare_and_process_set(df):\n",
    "    df['City'] = leCity.transform(df['City'])\n",
    "    castDates(df)\n",
    "    joined_12 = merge12(df)\n",
    "    joined_12 = drop_basis(joined_12)\n",
    "    return joined_12\n",
    "    \n",
    "    \n",
    "\n",
    "leCity = preprocessing.LabelEncoder()\n",
    "leCity.fit(joined_train['City'])\n",
    "joined_train_12 = prepare_and_process_set(joined_train)\n",
    "joined_test_12 = prepare_and_process_set(joined_test)\n",
    "# joined_train['City'] = leCity.transform(joined_train['City'])\n",
    "# castDates(joined_train)\n",
    "\n",
    "# joined_test['City'] = leCity.transform(joined_test['City'])\n",
    "# castDates(joined_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_train_12.to_pickle('joined_train_12_df.pickle')\n",
    "joined_test_12.to_pickle('joined_test_12_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_n_days(df, n):\n",
    "    \"\"\"Merge n days prior to each Validation Date in df. Returns df\"\"\"\n",
    "    shifted_list = [df.groupby(['City']).shift(-1*i) for i in range(1, n+1)]\n",
    "    for i in range(n):\n",
    "        back = -1*(i+1)\n",
    "        df = df.join(shifted_list[i].rename(columns=lambda x: x+f\"_{back}\"))\n",
    "        df.drop(f'Validity date_{back}', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "train_df_ts_list = [merge_n_days(joined_train_12, i) for i in range(1, 10)]\n",
    "test_df_ts_list = [merge_n_days(joined_test_12, i) for i in range(1, 10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a linear Regression model\n",
    "reg = LinearRegression()\n",
    "# reg.fit(joined_train, train_Tmax_obs['observedMaxTemp'])\n",
    "reg.fit(joined_train_12, train_Tmax_obs['observedMaxTemp'])  # only for 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = reg.predict(joined_test_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.65650385966\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the model\n",
    "\n",
    "# Calculate rmse by the difference square of the model predicted values and the actual values (obs)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(test_Tmax_obs['observedMaxTemp'], predicted_values))\n",
    "\n",
    "print(rmse)\n",
    "\n",
    "# old: 1.75672391465"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame containing 2 columns:\n",
    "# 1. key -concatenation of station name and date\n",
    "# 2. predicted values\n",
    "\n",
    "# dates = joined_test['Validity date'].apply(lambda x: datetime.fromtimestamp(x).strftime('%d-%m-%y') + '_')\n",
    "# cities = leCity.inverse_transform(joined_test['City'])\n",
    "# prediction_data = pd.DataFrame()\n",
    "# prediction_data['validityDate_city'] = dates + cities\n",
    "# prediction_data['predictedMaxTemp'] = predicted_values\n",
    "\n",
    "# prediction_data.to_csv(r'sampleSubmission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
