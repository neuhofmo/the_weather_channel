{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare joined datasets for meteorology challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# working_folder = r'..\\kaggle_data'\n",
    "# os.chdir(working_folder)  # change to your own folder\n",
    "os.chdir(r'C:\\Users\\User\\Documents\\DMBI_hackathon_2018\\the_weather_channel-master\\the_weather_channel-master\\kaggle_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "\n",
    "# train sets\n",
    "Tmax_train = pd.read_csv(r'train_maxTemp.csv')\n",
    "Tmin_train = pd.read_csv(r'train_minTemp.csv')\n",
    "Wind_train = pd.read_csv(r'train_Wind.csv')\n",
    "Humidity_train = pd.read_csv(r'train_Humidity.csv')\n",
    "\n",
    "# test sets\n",
    "Tmax_test = pd.read_csv(r'test_maxTemp.csv')\n",
    "Tmin_test = pd.read_csv(r'test_minTemp.csv')\n",
    "Wind_test = pd.read_csv(r'test_Wind.csv')\n",
    "Humidity_test = pd.read_csv(r'test_Humidity.csv')\n",
    "\n",
    "# obs values\n",
    "train_Tmax_obs = pd.read_csv(r'train_label.csv')\n",
    "test_Tmax_obs = pd.read_csv(r'test_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join data sets by keys: Form, Validity date, City\n",
    "# joined_train = pd.merge(Tmax_train, Tmin_train.drop(columns=['Basis date']), on=['Time', 'Validity date', 'City'], suffixes=('_tmax', '_tmin'))\n",
    "\n",
    "joined_train_1 = pd.merge(Tmax_train, Tmin_train, on=['Time', 'Validity date', 'City'], suffixes=('_tmax', '_tmin'))\n",
    "joined_train_2 = pd.merge(joined_train_1, Wind_train, on=['Time', 'Validity date', 'City'], suffixes=('', '_wind'))\n",
    "joined_train = pd.merge(joined_train_2, Humidity_train, on=['Time', 'Validity date', 'City'], suffixes=('', '_humidity'))\n",
    "joined_train.columns = ['Time', 'Basis date_tmax', 'Validity date', 'City',\n",
    "       'Persist. value_tmax', 'EC_tmax', 'CO_tmax', 'C3_tmax', 'OH_tmax',\n",
    "       'Basis date_tmin', 'Persist. value_tmin', 'EC_tmin', 'CO_tmin',\n",
    "       'C3_tmin', 'OH_tmin', 'Basis date_wind', 'Persist. value_wind', 'EC_wind', 'CO_wind', 'C3_wind',\n",
    "       'OH_wind', 'Basis date_humidity', 'Persist. value_humidity', 'EC_humidity',\n",
    "       'C3_humidity']\n",
    "\n",
    "joined_test = pd.merge(Tmax_test, Tmin_test, on=['Time', 'Validity date', 'City'], suffixes=('_tmax', '_tmin'))\n",
    "joined_test = pd.merge(joined_test, Wind_test, on=['Time', 'Validity date', 'City'], suffixes=('', '_wind'))\n",
    "joined_test = pd.merge(joined_test, Humidity_test, on=['Time', 'Validity date', 'City'], suffixes=('', '_humidity'))\n",
    "joined_test.columns = ['Time', 'Basis date_tmax', 'Validity date', 'City',\n",
    "       'Persist. value_tmax', 'EC_tmax', 'CO_tmax', 'C3_tmax', 'OH_tmax',\n",
    "       'Basis date_tmin', 'Persist. value_tmin', 'EC_tmin', 'CO_tmin',\n",
    "       'C3_tmin', 'OH_tmin', 'Basis date_wind', 'Persist. value_wind', 'EC_wind', 'CO_wind', 'C3_wind',\n",
    "       'OH_wind', 'Basis date_humidity', 'Persist. value_humidity', 'EC_humidity',\n",
    "       'C3_humidity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting string values to float (the model can fit only float values)\n",
    "\n",
    "# casting 'Validity date' to datetime.timestamp\n",
    "def castDates(df):\n",
    "    df['Validity date'] = df['Validity date'].apply(lambda x: (datetime.strptime(x, '%d-%m-%y')).timestamp())\n",
    "\n",
    "def merge12(df):\n",
    "    df1 = df[df['Time']== 1]\n",
    "    df2 = df[df['Time']== 2]\n",
    "    merged_df = pd.merge(df1, df2, on=['Validity date', 'City'], suffixes=('_1', '_2'))\n",
    "    merged_df.drop(['Time_1', 'Time_2'], axis=1, inplace=True)\n",
    "    return merged_df\n",
    "\n",
    "def drop_basis(df):\n",
    "    return df.drop([x for x in df.columns if x.startswith('Basis date')], axis=1)\n",
    "\n",
    "def prepare_and_process_set(df):\n",
    "    df['City'] = leCity.transform(df['City'])\n",
    "    castDates(df)\n",
    "    joined_12 = merge12(df)\n",
    "    joined_12 = drop_basis(joined_12)\n",
    "    return joined_12\n",
    "    \n",
    "leCity = preprocessing.LabelEncoder()\n",
    "leCity.fit(joined_train['City'])\n",
    "joined_train = prepare_and_process_set(joined_train)\n",
    "joined_test = prepare_and_process_set(joined_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validity date</th>\n",
       "      <th>City</th>\n",
       "      <th>Persist. value_tmax_1</th>\n",
       "      <th>EC_tmax_1</th>\n",
       "      <th>CO_tmax_1</th>\n",
       "      <th>C3_tmax_1</th>\n",
       "      <th>OH_tmax_1</th>\n",
       "      <th>Persist. value_tmin_1</th>\n",
       "      <th>EC_tmin_1</th>\n",
       "      <th>CO_tmin_1</th>\n",
       "      <th>...</th>\n",
       "      <th>C3_humidity_2</th>\n",
       "      <th>cityID</th>\n",
       "      <th>stationID</th>\n",
       "      <th>name</th>\n",
       "      <th>E</th>\n",
       "      <th>N</th>\n",
       "      <th>elevation</th>\n",
       "      <th>elevationWindMet</th>\n",
       "      <th>CoastalDist</th>\n",
       "      <th>archiveID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.451686e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Afula</td>\n",
       "      <td>35.277</td>\n",
       "      <td>32.596</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>5811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.451772e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Afula</td>\n",
       "      <td>35.277</td>\n",
       "      <td>32.596</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>5811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.451858e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Afula</td>\n",
       "      <td>35.277</td>\n",
       "      <td>32.596</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>5811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.451945e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Afula</td>\n",
       "      <td>35.277</td>\n",
       "      <td>32.596</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>5811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.452031e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Afula</td>\n",
       "      <td>35.277</td>\n",
       "      <td>32.596</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "      <td>33.34</td>\n",
       "      <td>5811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Validity date  City  Persist. value_tmax_1  EC_tmax_1  CO_tmax_1  \\\n",
       "0   1.451686e+09     0                     12       11.0       11.0   \n",
       "1   1.451772e+09     0                     11       11.0       11.0   \n",
       "2   1.451858e+09     0                     15       14.0       16.0   \n",
       "3   1.451945e+09     0                     16       19.0       17.0   \n",
       "4   1.452031e+09     0                     20       20.0       18.0   \n",
       "\n",
       "   C3_tmax_1  OH_tmax_1  Persist. value_tmin_1  EC_tmin_1  CO_tmin_1  \\\n",
       "0       12.0       13.0                    6.0        7.0        6.0   \n",
       "1       14.0       13.0                    7.0        9.0        8.0   \n",
       "2       14.0       17.0                    6.0        8.0       11.0   \n",
       "3       17.0       20.0                   10.0        9.0       10.0   \n",
       "4       18.0       20.0                    6.0        8.0       12.0   \n",
       "\n",
       "     ...      C3_humidity_2  cityID  stationID   name       E       N  \\\n",
       "0    ...                 35       0         16  Afula  35.277  32.596   \n",
       "1    ...                 51       0         16  Afula  35.277  32.596   \n",
       "2    ...                 58       0         16  Afula  35.277  32.596   \n",
       "3    ...                 49       0         16  Afula  35.277  32.596   \n",
       "4    ...                 45       0         16  Afula  35.277  32.596   \n",
       "\n",
       "   elevation   elevationWindMet  CoastalDist  archiveID  \n",
       "0          60                70        33.34       5811  \n",
       "1          60                70        33.34       5811  \n",
       "2          60                70        33.34       5811  \n",
       "3          60                70        33.34       5811  \n",
       "4          60                70        33.34       5811  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding city data from the IMS' site\n",
    "\n",
    "stationsData = pd.read_csv(r'stations_dist.csv')\n",
    "joined_train = joined_train.merge(stationsData, left_on='City', right_on='cityID',how='outer')\n",
    "joined_test = joined_test.merge(stationsData, left_on='City', right_on='cityID',how='outer')\n",
    "\n",
    "joined_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3_6\\lib\\site-packages\\pandas\\core\\indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Generate seasonal features\n",
    "\n",
    "# joined_train = pd.read_pickle(r'joined_train_12_daily_features_df.pickle')\n",
    "# joined_test  = pd.read_pickle(r'joined_test_12_daily_features_df.pickle')\n",
    "joined_train = joined_train.sort_values(['Validity date','cityID'])\n",
    "joined_train['season'] = 0\n",
    "startDayOfSeason = 0 \n",
    "endDayOfSeason = 59*15 \n",
    "joined_train.season.iloc[startDayOfSeason:endDayOfSeason+1]='Winter'\n",
    "startDayOfSeason, endDayOfSeason = endDayOfSeason, endDayOfSeason+92*15\n",
    "joined_train.season.iloc[startDayOfSeason+1:endDayOfSeason+1]='Spring'\n",
    "startDayOfSeason, endDayOfSeason = endDayOfSeason, endDayOfSeason+92*15\n",
    "joined_train.season.iloc[startDayOfSeason+1:endDayOfSeason+1]='Summer'\n",
    "startDayOfSeason, endDayOfSeason = endDayOfSeason, endDayOfSeason+91*15\n",
    "joined_train.season.iloc[startDayOfSeason+1:endDayOfSeason+1]='Autumn'\n",
    "startDayOfSeason, endDayOfSeason = endDayOfSeason, endDayOfSeason+90*15\n",
    "joined_train.season.iloc[startDayOfSeason+1:endDayOfSeason+1]='Winter'\n",
    "startDayOfSeason, endDayOfSeason = endDayOfSeason, endDayOfSeason+92*15\n",
    "joined_train.season.iloc[startDayOfSeason+1:endDayOfSeason+1]='Spring'\n",
    "startDayOfSeason, endDayOfSeason = endDayOfSeason, endDayOfSeason+92*15\n",
    "joined_train.season.iloc[startDayOfSeason+1:endDayOfSeason+1]='Summer'\n",
    "startDayOfSeason, endDayOfSeason = endDayOfSeason, endDayOfSeason+91*15\n",
    "joined_train.season.iloc[startDayOfSeason+1:endDayOfSeason+1]='Autumn'\n",
    "startDayOfSeason, endDayOfSeason = endDayOfSeason, endDayOfSeason+30*15\n",
    "joined_train.season.iloc[startDayOfSeason+1:endDayOfSeason+1]='Winter'\n",
    "\n",
    "joined_test = joined_test.sort_values(['Validity date','cityID'])\n",
    "joined_test['season'] = 0\n",
    "startDayOfSeason = 0 \n",
    "endDayOfSeason = 59*15 \n",
    "joined_test.season.iloc[startDayOfSeason:endDayOfSeason+1]='Winter'\n",
    "startDayOfSeason, endDayOfSeason = endDayOfSeason, endDayOfSeason+31*15\n",
    "joined_test.season.iloc[startDayOfSeason+1:endDayOfSeason+1]='Spring'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Validity date', 'Persist. value_tmax_1', 'EC_tmax_1', 'CO_tmax_1', 'C3_tmax_1', 'OH_tmax_1', 'Persist. value_tmin_1', 'EC_tmin_1', 'CO_tmin_1', 'C3_tmin_1', 'OH_tmin_1', 'Persist. value_wind_1', 'EC_wind_1', 'CO_wind_1', 'C3_wind_1', 'OH_wind_1', 'Persist. value_humidity_1', 'EC_humidity_1', 'C3_humidity_1', 'Persist. value_tmax_2', 'EC_tmax_2', 'CO_tmax_2', 'C3_tmax_2', 'OH_tmax_2', 'Persist. value_tmin_2', 'EC_tmin_2', 'CO_tmin_2', 'C3_tmin_2', 'OH_tmin_2', 'Persist. value_wind_2', 'EC_wind_2', 'CO_wind_2', 'C3_wind_2', 'OH_wind_2', 'Persist. value_humidity_2', 'EC_humidity_2', 'C3_humidity_2', 'cityID', 'stationID', 'name', 'E', 'N', 'elevation ', 'elevationWindMet', 'CoastalDist', 'archiveID', 'City_0', 'City_1', 'City_2', 'City_3', 'City_4', 'City_5', 'City_6', 'City_7', 'City_8', 'City_9', 'City_10', 'City_11', 'City_12', 'City_13', 'City_14', 'season_Spring', 'season_Winter', 'persist_tmax_daily_avg', 'models_tmax_daily_avg', 'models_tmax_1_avg', 'models_tmax_2_avg', 'persist_tmin_daily_avg', 'models_tmin_daily_avg', 'models_tmin_1_avg', 'models_tmin_2_avg', 'persist_wind_daily_avg', 'models_wind_daily_avg', 'models_wind_1_avg', 'models_wind_2_avg', 'persist_humidity_daily_avg', 'models_humidity_daily_avg', 'models_humidity_1_avg', 'models_humidity_2_avg', 'EC_range_temp_1', 'EC_range_temp_2', 'CO_range_temp_1', 'CO_range_temp_2', 'C3_range_temp_1', 'C3_range_temp_2', 'OH_range_temp_1', 'OH_range_temp_2', 'EC_daily_avg_temp', 'CO_daily_avg_temp', 'C3_daily_avg_temp', 'OH_daily_avg_temp', 'dist_persist_models_avg_tmax_daily', 'dist_persist_models_avg_tmax_1', 'dist_persist_models_avg_tmax_2', 'dist_persist_models_avg_tmin_daily', 'dist_persist_models_avg_tmin_1', 'dist_persist_models_avg_tmin_2', 'dist_persist_models_avg_wind_daily', 'dist_persist_models_avg_wind_1', 'dist_persist_models_avg_wind_2', 'dist_persist_models_avg_humidity_daily', 'dist_persist_models_avg_humidity_1', 'dist_persist_models_avg_humidity_2', 'reliable_models_tmax_daily_avg', 'reliable_models_tmax_1_avg', 'reliable_models_tmax_2_avg', 'reliable_models_tmin_daily_avg', 'reliable_models_tmin_1_avg', 'reliable_models_tmin_2_avg', 'reliable_models_wind_daily_avg', 'reliable_models_wind_1_avg', 'reliable_models_wind_2_avg']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validity date</th>\n",
       "      <th>Persist. value_tmax_1</th>\n",
       "      <th>EC_tmax_1</th>\n",
       "      <th>CO_tmax_1</th>\n",
       "      <th>C3_tmax_1</th>\n",
       "      <th>OH_tmax_1</th>\n",
       "      <th>Persist. value_tmin_1</th>\n",
       "      <th>EC_tmin_1</th>\n",
       "      <th>CO_tmin_1</th>\n",
       "      <th>C3_tmin_1</th>\n",
       "      <th>...</th>\n",
       "      <th>dist_persist_models_avg_humidity_2</th>\n",
       "      <th>reliable_models_tmax_daily_avg</th>\n",
       "      <th>reliable_models_tmax_1_avg</th>\n",
       "      <th>reliable_models_tmax_2_avg</th>\n",
       "      <th>reliable_models_tmin_daily_avg</th>\n",
       "      <th>reliable_models_tmin_1_avg</th>\n",
       "      <th>reliable_models_tmin_2_avg</th>\n",
       "      <th>reliable_models_wind_daily_avg</th>\n",
       "      <th>reliable_models_wind_1_avg</th>\n",
       "      <th>reliable_models_wind_2_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.451686e+09</td>\n",
       "      <td>12</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>8.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>1.451686e+09</td>\n",
       "      <td>15</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>12.166667</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>10.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1.451686e+09</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>10.833333</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>11.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2187</th>\n",
       "      <td>1.451686e+09</td>\n",
       "      <td>15</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.166667</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>7.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>1.451686e+09</td>\n",
       "      <td>19</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>5.833333</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.833333</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Validity date  Persist. value_tmax_1  EC_tmax_1  CO_tmax_1  C3_tmax_1  \\\n",
       "0      1.451686e+09                     12       11.0       11.0       12.0   \n",
       "729    1.451686e+09                     15       14.0       12.0       14.0   \n",
       "1458   1.451686e+09                     10       10.0       11.0       12.0   \n",
       "2187   1.451686e+09                     15       11.0       14.0       14.0   \n",
       "2916   1.451686e+09                     19       12.0       14.0       15.0   \n",
       "\n",
       "      OH_tmax_1  Persist. value_tmin_1  EC_tmin_1  CO_tmin_1  C3_tmin_1  \\\n",
       "0          13.0                    6.0        7.0        6.0        6.0   \n",
       "729        14.0                   10.0       12.0        9.0       10.0   \n",
       "1458        9.0                    5.0        7.0        7.0        7.0   \n",
       "2187       13.0                    8.0        8.0        7.0        8.0   \n",
       "2916       13.0                    9.0        4.0        7.0        6.0   \n",
       "\n",
       "                 ...              dist_persist_models_avg_humidity_2  \\\n",
       "0                ...                                            29.5   \n",
       "729              ...                                            29.5   \n",
       "1458             ...                                            28.0   \n",
       "2187             ...                                            32.0   \n",
       "2916             ...                                             7.0   \n",
       "\n",
       "      reliable_models_tmax_daily_avg  reliable_models_tmax_1_avg  \\\n",
       "0                          11.666667                   11.333333   \n",
       "729                        13.333333                   13.333333   \n",
       "1458                       10.833333                   11.000000   \n",
       "2187                       13.166667                   13.000000   \n",
       "2916                       13.666667                   13.666667   \n",
       "\n",
       "      reliable_models_tmax_2_avg  reliable_models_tmin_daily_avg  \\\n",
       "0                      12.000000                        6.500000   \n",
       "729                    13.333333                       10.833333   \n",
       "1458                   10.666667                        6.833333   \n",
       "2187                   13.333333                        7.666667   \n",
       "2916                   13.666667                        5.833333   \n",
       "\n",
       "      reliable_models_tmin_1_avg  reliable_models_tmin_2_avg  \\\n",
       "0                       6.333333                    6.666667   \n",
       "729                    10.333333                   11.333333   \n",
       "1458                    7.000000                    6.666667   \n",
       "2187                    7.666667                    7.666667   \n",
       "2916                    5.666667                    6.000000   \n",
       "\n",
       "      reliable_models_wind_daily_avg  reliable_models_wind_1_avg  \\\n",
       "0                           7.500000                    6.666667   \n",
       "729                        12.166667                   13.666667   \n",
       "1458                       10.500000                    9.333333   \n",
       "2187                        4.666667                    5.000000   \n",
       "2916                        6.833333                    6.666667   \n",
       "\n",
       "      reliable_models_wind_2_avg  \n",
       "0                       8.333333  \n",
       "729                    10.666667  \n",
       "1458                   11.666667  \n",
       "2187                    4.333333  \n",
       "2916                    7.000000  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating per day features\n",
    "# joined_train = pd.read_pickle(r'joined_train_with_metro_data.pickle')\n",
    "# joined_test = pd.read_pickle(r'joined_test_with_metro_data.pickle')\n",
    "\n",
    "def genModelFeatAvg():\n",
    "    for df in [joined_train,joined_test]:\n",
    "        for feat in ['tmax','tmin','wind','humidity']:\n",
    "#             Avg for each persist feat when 1 and 2 are combined\n",
    "            df['persist_'+feat+'_daily_avg']=sum([(df['Persist. value_'+feat+'_'+i]) for i in [\"1\",\"2\"]])/2\n",
    "#             Avg for each feat when 1 and 2 are combined\n",
    "            if feat=='humidity':\n",
    "                df['models_'+feat+'_daily_avg']=sum([(df['EC_'+feat+'_'+i]+df['C3_'+feat+'_'+i]) for i in [\"1\",\"2\"]])/4\n",
    "            else:\n",
    "                df['models_'+feat+'_daily_avg']=sum([(df['EC_'+feat+'_'+i]+df['CO_'+feat+'_'+i]+df['C3_'+feat+'_'+i]+df['OH_'+feat+'_'+i]) for i in [\"1\",\"2\"]])/8\n",
    "#             Avg for each feat when 1 and 2 are apart\n",
    "            for i in ['1','2']:\n",
    "                if feat=='humidity':\n",
    "                    df['models_'+feat+'_'+i+'_avg']=(df['EC_'+feat+'_'+i]+df['C3_'+feat+'_'+i])/2\n",
    "                else:\n",
    "                    df['models_'+feat+'_'+i+'_avg']=(df['EC_'+feat+'_'+i]+df['CO_'+feat+'_'+i]+df['C3_'+feat+'_'+i]+df['OH_'+feat+'_'+i])/4\n",
    "\n",
    "def genTempRange():\n",
    "    for df in [joined_train,joined_test]:\n",
    "        for model in ['EC','CO','C3','OH']:\n",
    "            for i in ['1','2']:\n",
    "                df[model+'_range_temp_'+i]=df[model+'_tmax_'+i]-df[model+'_tmin_'+i]\n",
    "                \n",
    "def genDayTempAvg():\n",
    "    for df in [joined_train,joined_test]:\n",
    "        for model in ['EC','CO','C3','OH']:\n",
    "            df[model+'_daily_avg_temp']=sum([df[model+'_tmax_'+i]+df[model+'_tmin_'+i] for i in [\"1\",\"2\"]])/4\n",
    "def genDistPersistModelsAvg():\n",
    "    for df in [joined_train,joined_test]:\n",
    "        for feat in ['tmax','tmin','wind','humidity']:\n",
    "            df['dist_persist_models_avg_'+feat+'_daily']=abs(df['models_'+feat+'_daily_avg']-df['persist_'+feat+'_daily_avg'])\n",
    "            for i in ['1','2']:\n",
    "                df['dist_persist_models_avg_'+feat+'_'+i]=abs(df['models_'+feat+'_'+i+'_avg']-df['Persist. value_'+feat+'_'+i])\n",
    "def reliableModelsAvg():\n",
    "    for df in [joined_train,joined_test]:\n",
    "        for feat in ['tmax','tmin','wind']:\n",
    "#             Avg for each feat when 1 and 2 are combined\n",
    "            df['reliable_models_'+feat+'_daily_avg']=sum([(df['EC_'+feat+'_'+i]+df['CO_'+feat+'_'+i]+df['C3_'+feat+'_'+i]) for i in [\"1\",\"2\"]])/6\n",
    "#             Avg for each feat when 1 and 2 are apart\n",
    "            for i in ['1','2']:\n",
    "                df['reliable_models_'+feat+'_'+i+'_avg']=(df['EC_'+feat+'_'+i]+df['CO_'+feat+'_'+i]+df['C3_'+feat+'_'+i])/3\n",
    "joined_train = pd.get_dummies(joined_train, columns=['City'])\n",
    "joined_test = pd.get_dummies(joined_test, columns=['City'])\n",
    "\n",
    "joined_train = pd.get_dummies(joined_train, columns=['season'])\n",
    "joined_test = pd.get_dummies(joined_test, columns=['season'])\n",
    "\n",
    "genModelFeatAvg()\n",
    "genTempRange()\n",
    "genDayTempAvg()\n",
    "genDistPersistModelsAvg()\n",
    "reliableModelsAvg()\n",
    "print(list(joined_test.columns.values))\n",
    "joined_train.head()\n",
    "# joined_train.to_pickle('joined_train_12_daily_features_df.pickle')\n",
    "# joined_test.to_pickle('joined_test_12_daily_features_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3_6\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def merge_n_days(df, n):\n",
    "    df_list = []  # init\n",
    "    for city in df['name'].unique():\n",
    "        # subset to city\n",
    "        local_df = df[df['name'] == city]\n",
    "        local_df.drop(['cityID', 'name', 'stationID', 'archiveID'], axis=1, inplace=True)\n",
    "        sorted_local_df = local_df.sort_values(['Validity date'], ascending=False)\n",
    "        shifted_df_list = [sorted_local_df.shift(-1*i) for i in range(1, n+1)]  # for each day\n",
    "        \n",
    "        for i in range(n):  # for each day\n",
    "            shifted_df = shifted_df_list[i]\n",
    "            back = -1*(i+1)\n",
    "            sorted_local_df = sorted_local_df.join(shifted_df.rename(columns=lambda x: x+f\"_{back}\"))\n",
    "            sorted_local_df.drop([f'Validity date_{back}'], axis=1, inplace=True)\n",
    "            sorted_local_df.drop([f'City_{i}_{back}' for i in range(15)], axis=1, inplace=True)\n",
    "            sorted_local_df.drop([f'CoastalDist_{back}', f'elevation _{back}', f'N_{back}', f'E_{back}', ], axis=1, inplace=True)\n",
    "            \n",
    "        df_list.append(sorted_local_df)\n",
    "    return pd.concat(df_list)  # for all cities\n",
    "\n",
    "\n",
    "def create_list_of_1_to_n_timeseries(train_df, test_df, n):\n",
    "    ts_df_train_list = [merge_n_days(train_df, i) for i in range(1, n)]\n",
    "    ts_df_test_list = [merge_n_days(test_df, i) for i in range(1, n)]\n",
    "    return ts_df_train_list, ts_df_test_list\n",
    "\n",
    "# change here to your train + test\n",
    "ts_df_train_list, ts_df_test_list = create_list_of_1_to_n_timeseries(joined_train, joined_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = joined_train.drop(['cityID', 'name', 'stationID', 'archiveID'], axis=1)\n",
    "X_test = joined_test.drop(['cityID', 'name', 'stationID', 'archiveID'], axis=1)\n",
    "X_test['season_Autumn'] = 0\n",
    "X_test['season_Summer'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a linear Regression model\n",
    "reg = LinearRegression()\n",
    "# reg.fit(joined_train, train_Tmax_obs['observedMaxTemp'])\n",
    "reg.fit(X_train, train_Tmax_obs['observedMaxTemp'])  # only for 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.06829588506\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of the model\n",
    "\n",
    "# Calculate rmse by the difference square of the model predicted values and the actual values (obs)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(test_Tmax_obs['observedMaxTemp'], predicted_values))\n",
    "\n",
    "print(rmse)\n",
    "\n",
    "# old: 1.75672391465\n",
    "# old: 1.65650385966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale, PolynomialFeatures\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, average_precision_score, adjusted_rand_score, adjusted_mutual_info_score, confusion_matrix\n",
    "# polynomial\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "# X_train_poly_df = pd.DataFrame(X_train_poly)\n",
    "# X_train_poly_df_1hot = pd.get_dummies(X_train_poly_df, columns=['City'])\n",
    "\n",
    "X_test_poly = poly.fit_transform(X_test)\n",
    "# X_test_poly_df = pd.DataFrame(X_test_poly)\n",
    "# X_test_poly_df_1hot = pd.get_dummies(X_test_poly_df, columns=['City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634.238504696\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "# reg.fit(joined_train, train_Tmax_obs['observedMaxTemp'])\n",
    "reg.fit(X_train_poly, train_Tmax_obs['observedMaxTemp'])  # only for 1\n",
    "predicted_values = reg.predict(X_test_poly)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(test_Tmax_obs['observedMaxTemp'], predicted_values))\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5866561428.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3_6\\lib\\site-packages\\sklearn\\preprocessing\\data.py:164: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "# scaled\n",
    "reg = LinearRegression()\n",
    "# reg.fit(joined_train, train_Tmax_obs['observedMaxTemp'])\n",
    "reg.fit(scale(X_train), train_Tmax_obs['observedMaxTemp'])  # only for 1\n",
    "predicted_values = reg.predict(scale(X_test))\n",
    "rmse = np.sqrt(metrics.mean_squared_error(test_Tmax_obs['observedMaxTemp'], predicted_values))\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validity date\n",
      "Persist. value_tmax_1\n",
      "EC_tmax_1\n",
      "CO_tmax_1\n",
      "C3_tmax_1\n",
      "OH_tmax_1\n",
      "Persist. value_tmin_1\n",
      "EC_tmin_1\n",
      "CO_tmin_1\n",
      "C3_tmin_1\n",
      "OH_tmin_1\n",
      "Persist. value_wind_1\n",
      "EC_wind_1\n",
      "CO_wind_1\n",
      "C3_wind_1\n",
      "OH_wind_1\n",
      "Persist. value_humidity_1\n",
      "EC_humidity_1\n",
      "C3_humidity_1\n",
      "Persist. value_tmax_2\n",
      "EC_tmax_2\n",
      "CO_tmax_2\n",
      "C3_tmax_2\n",
      "OH_tmax_2\n",
      "Persist. value_tmin_2\n",
      "EC_tmin_2\n",
      "CO_tmin_2\n",
      "C3_tmin_2\n",
      "OH_tmin_2\n",
      "Persist. value_wind_2\n",
      "EC_wind_2\n",
      "CO_wind_2\n",
      "C3_wind_2\n",
      "OH_wind_2\n",
      "Persist. value_humidity_2\n",
      "EC_humidity_2\n",
      "C3_humidity_2\n",
      "E\n",
      "N\n",
      "elevation \n",
      "elevationWindMet\n",
      "CoastalDist\n",
      "City_0\n",
      "City_1\n",
      "City_2\n",
      "City_3\n",
      "City_4\n",
      "City_5\n",
      "City_6\n",
      "City_7\n",
      "City_8\n",
      "City_9\n",
      "City_10\n",
      "City_11\n",
      "City_12\n",
      "City_13\n",
      "City_14\n",
      "season_Autumn\n",
      "season_Spring\n",
      "season_Summer\n",
      "season_Winter\n",
      "persist_tmax_daily_avg\n",
      "models_tmax_daily_avg\n",
      "models_tmax_1_avg\n",
      "models_tmax_2_avg\n",
      "persist_tmin_daily_avg\n",
      "models_tmin_daily_avg\n",
      "models_tmin_1_avg\n",
      "models_tmin_2_avg\n",
      "persist_wind_daily_avg\n",
      "models_wind_daily_avg\n",
      "models_wind_1_avg\n",
      "models_wind_2_avg\n",
      "persist_humidity_daily_avg\n",
      "models_humidity_daily_avg\n",
      "models_humidity_1_avg\n",
      "models_humidity_2_avg\n",
      "EC_range_temp_1\n",
      "EC_range_temp_2\n",
      "CO_range_temp_1\n",
      "CO_range_temp_2\n",
      "C3_range_temp_1\n",
      "C3_range_temp_2\n",
      "OH_range_temp_1\n",
      "OH_range_temp_2\n",
      "EC_daily_avg_temp\n",
      "CO_daily_avg_temp\n",
      "C3_daily_avg_temp\n",
      "OH_daily_avg_temp\n",
      "dist_persist_models_avg_tmax_daily\n",
      "dist_persist_models_avg_tmax_1\n",
      "dist_persist_models_avg_tmax_2\n",
      "dist_persist_models_avg_tmin_daily\n",
      "dist_persist_models_avg_tmin_1\n",
      "dist_persist_models_avg_tmin_2\n",
      "dist_persist_models_avg_wind_daily\n",
      "dist_persist_models_avg_wind_1\n",
      "dist_persist_models_avg_wind_2\n",
      "dist_persist_models_avg_humidity_daily\n",
      "dist_persist_models_avg_humidity_1\n",
      "dist_persist_models_avg_humidity_2\n",
      "reliable_models_tmax_daily_avg\n",
      "reliable_models_tmax_1_avg\n",
      "reliable_models_tmax_2_avg\n",
      "reliable_models_tmin_daily_avg\n",
      "reliable_models_tmin_1_avg\n",
      "reliable_models_tmin_2_avg\n",
      "reliable_models_wind_daily_avg\n",
      "reliable_models_wind_1_avg\n",
      "reliable_models_wind_2_avg\n"
     ]
    }
   ],
   "source": [
    "for col in X_train.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['E', 'N', 'elevation', 'elevationWindMet', 'CoastalDist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Validity date', 'Persist. value_tmax_1', 'EC_tmax_1', 'CO_tmax_1',\n",
       "       'C3_tmax_1', 'OH_tmax_1', 'Persist. value_tmin_1', 'EC_tmin_1',\n",
       "       'CO_tmin_1', 'C3_tmin_1',\n",
       "       ...\n",
       "       'reliable_models_tmax_1_avg', 'reliable_models_tmax_2_avg',\n",
       "       'reliable_models_tmin_daily_avg', 'reliable_models_tmin_1_avg',\n",
       "       'reliable_models_tmin_2_avg', 'reliable_models_wind_daily_avg',\n",
       "       'reliable_models_wind_1_avg', 'reliable_models_wind_2_avg',\n",
       "       'season_Autumn', 'season_Summer'],\n",
       "      dtype='object', length=110)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new data frame containing 2 columns:\n",
    "# 1. key -concatenation of station name and date\n",
    "# 2. predicted values\n",
    "\n",
    "# dates = joined_test['Validity date'].apply(lambda x: datetime.fromtimestamp(x).strftime('%d-%m-%y') + '_')\n",
    "# cities = leCity.inverse_transform(joined_test['City'])\n",
    "# prediction_data = pd.DataFrame()\n",
    "# prediction_data['validityDate_city'] = dates + cities\n",
    "# prediction_data['predictedMaxTemp'] = predicted_values\n",
    "\n",
    "# prediction_data.to_csv(r'sampleSubmission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
