{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\dev\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import h5py\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, \\\n",
    "        BatchNormalization, GRU, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('..//datasets//joined_train_with_metro_data.pickle','rb') as f:\n",
    "    df_features_train = pickle.load(f)\n",
    "    \n",
    "with open('..//datasets//joined_test_with_metro_data.pickle','rb') as f:\n",
    "    df_features_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asass 02\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_synoptic = pd.read_csv('synoptic_classification_1948-14_May_2017.csv')\n",
    "df_synoptic = df_synoptic.loc[:,['Month','Day','2016','2017']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('%d format: a number is required, not Series', 'occurred at index Month')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9d6d0380a8c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mMonth_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_ordered_month\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'01'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'02'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'03'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'04'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'05'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'06'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'07'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'08'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'09'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'10'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'11'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'12'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_synoptic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Month'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_synoptic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Month'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mMonth_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf_synoptic2016\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_synoptic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Month'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Day'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2016'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'%02d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   4875\u001b[0m                         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4876\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4877\u001b[1;33m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[0;32m   4878\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4879\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\dev\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4971\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4972\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4973\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4974\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4975\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-9d6d0380a8c4>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mMonth_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_ordered_month\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'01'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'02'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'03'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'04'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'05'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'06'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'07'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'08'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'09'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'10'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'11'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'12'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdf_synoptic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Month'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_synoptic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Month'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mMonth_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf_synoptic2016\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_synoptic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Month'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Day'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'2016'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'%02d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: ('%d format: a number is required, not Series', 'occurred at index Month')"
     ]
    }
   ],
   "source": [
    "unique_ordered_month = []\n",
    "for word in df_synoptic['Month']:\n",
    "    if word not in unique_ordered_month:\n",
    "        unique_ordered_month.append(word)\n",
    "Month_dict = dict(zip(unique_ordered_month, ['01','02','03','04','05','06','07','08','09','10','11','12']))\n",
    "df_synoptic['Month'] = df_synoptic['Month'].apply(lambda x:Month_dict[x])\n",
    "df_synoptic2016 = df_synoptic[['Month','Day','2016']].apply(lambda x: '%02d' % (x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Validity date', 'Persist. value_tmax_1', 'EC_tmax_1', 'CO_tmax_1',\n",
       "       'C3_tmax_1', 'OH_tmax_1', 'Persist. value_tmin_1', 'EC_tmin_1',\n",
       "       'CO_tmin_1', 'C3_tmin_1', 'OH_tmin_1', 'Persist. value_wind_1',\n",
       "       'EC_wind_1', 'CO_wind_1', 'C3_wind_1', 'OH_wind_1',\n",
       "       'Persist. value_humidity_1', 'EC_humidity_1', 'C3_humidity_1',\n",
       "       'Persist. value_tmax_2', 'EC_tmax_2', 'CO_tmax_2', 'C3_tmax_2',\n",
       "       'OH_tmax_2', 'Persist. value_tmin_2', 'EC_tmin_2', 'CO_tmin_2',\n",
       "       'C3_tmin_2', 'OH_tmin_2', 'Persist. value_wind_2', 'EC_wind_2',\n",
       "       'CO_wind_2', 'C3_wind_2', 'OH_wind_2', 'Persist. value_humidity_2',\n",
       "       'EC_humidity_2', 'C3_humidity_2', 'cityID', 'stationID', 'name', 'E',\n",
       "       'N', 'elevation ', 'elevationWindMet', 'CoastalDist', 'archiveID',\n",
       "       'City_0', 'City_1', 'City_2', 'City_3', 'City_4', 'City_5', 'City_6',\n",
       "       'City_7', 'City_8', 'City_9', 'City_10', 'City_11', 'City_12',\n",
       "       'City_13', 'City_14'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_input = ['Persist. value_tmax_1', 'EC_tmax_1', 'CO_tmax_1',\n",
    "       'C3_tmax_1', 'OH_tmax_1', 'Persist. value_tmin_1', 'EC_tmin_1',\n",
    "       'CO_tmin_1', 'C3_tmin_1', 'OH_tmin_1', 'Persist. value_wind_1',\n",
    "       'EC_wind_1', 'CO_wind_1', 'C3_wind_1', 'OH_wind_1',\n",
    "       'Persist. value_humidity_1', 'EC_humidity_1', 'C3_humidity_1',\n",
    "       'Persist. value_tmax_2', 'EC_tmax_2', 'CO_tmax_2', 'C3_tmax_2',\n",
    "       'OH_tmax_2', 'Persist. value_tmin_2', 'EC_tmin_2', 'CO_tmin_2',\n",
    "       'C3_tmin_2', 'OH_tmin_2', 'Persist. value_wind_2', 'EC_wind_2',\n",
    "       'CO_wind_2', 'C3_wind_2', 'OH_wind_2', 'Persist. value_humidity_2',\n",
    "       'EC_humidity_2', 'C3_humidity_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_features_train)/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5811\n",
       "1000    3014\n",
       "2000    7841\n",
       "3000    9974\n",
       "4000    9476\n",
       "5000     850\n",
       "6000    2523\n",
       "7000    8229\n",
       "8000    4741\n",
       "9000    1980\n",
       "Name: archiveID, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_train.iloc[range(0,10000,1000)]['archiveID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_cities(df_per_city,feature_names_input):\n",
    "    col_names = ['Validity date'] + feature_names_input\n",
    "    for val_date in df_per_city['Validity date']:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jan</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jan</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jan</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jan</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jan</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  Day  2016  2017\n",
       "0   Jan    1    11   1.0\n",
       "1   Jan    2     9  17.0\n",
       "2   Jan    3    15   1.0\n",
       "3   Jan    4     7   1.0\n",
       "4   Jan    5    10   3.0\n",
       "5   Jan    6     7   9.0\n",
       "6   Jan    7    16   1.0\n",
       "7   Jan    8    14  14.0\n",
       "8   Jan    9     8  16.0\n",
       "9   Jan   10     1   7.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_synoptic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X, Y):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X[train], Y[train], epochs=150, batch_size=10, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X[test], Y[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
