{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import h5py\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, \\\n",
    "        BatchNormalization, GRU, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train/val data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### partition to train/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precent_train = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the seed HAS to be right above the np.random.permutation\n",
    "np.random.seed(seed=17)\n",
    "permutated_filenames = list(np.random.permutation(filenames))\n",
    "train_filenames = permutated_filenames[:round(len(filenames)*precent_train/100.0)]\n",
    "val_filenames = permutated_filenames[round(len(filenames)*precent_train/100.0):]\n",
    "train_inds = np.nonzero(df_data['fromFile'].apply(lambda x: x in train_filenames))\n",
    "val_inds = np.nonzero(df_data['fromFile'].apply(lambda x: x in val_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### translate df to X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = df_data.iloc[train_inds[0]]\n",
    "df_data_val = df_data.iloc[val_inds[0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing before LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sequences.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_feature_sequences = pd.get_dummies(concat_temp.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_sequences1 = Input(shape=(10,50,))\n",
    "\n",
    "# gru_1 = GRU(units=16, return_sequences=True)(input_sequences1)\n",
    "# gru_2 = GRU(units=16, return_sequences=True)(gru_1)\n",
    "# reshape_1 = Reshape(target_shape=(10,16,1))(gru_2)\n",
    "\n",
    "# pool1 = MaxPooling2D(pool_size=(10,4), strides=(1,4))(reshape_1)\n",
    "# pool_gru = Reshape(target_shape=(1,4))(pool1)\n",
    "\n",
    "# flatten_gru = Flatten()(pool_gru)\n",
    "\n",
    "# output_gru = Dense(4, activation='softmax')(flatten_gru)\n",
    "# gru_model = Model(inputs=[input_sequences1], outputs=[output_gru])\n",
    "# gru_model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "# gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences1 = Input(shape=(20,120,))\n",
    "\n",
    "gru_1 = GRU(units=100, return_sequences=True)(input_sequences1)\n",
    "gru_2 = GRU(units=30)(gru_1)\n",
    "\n",
    "dropout_gru1 = Dropout(0.3)(gru_2)\n",
    "\n",
    "dense_gru = Dense(20, activation='tanh')(dropout_gru1)\n",
    "\n",
    "output_gru = Dense(4, activation='softmax')(dense_gru)\n",
    "gru_model = Model(inputs=[input_sequences1], outputs=[output_gru])\n",
    "gru_model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_cb = EarlyStopping(monitor='val_loss', patience=35, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gru_model.fit(np.swapaxes(np.array(list(feature_sequences)), 1, 2), y_feature_sequences.values, \\\n",
    "#             epochs=1000, validation_split=0.2, batch_size=20, callbacks=[early_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model.fit(np.array(list(feature_sequences)), y_feature_sequences.values, \\\n",
    "            epochs=1000, validation_split=0.2, batch_size=50, callbacks=[early_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(feature_sequences)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of GRU code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
